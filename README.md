# web-scraping-precios-de-retailers
Automatization para extraer los precios de la competencia y especificaciones en el top 3 de retailers de Colombia
Web Scraping AC LATAM ‚Äî Resumen t√©cnico (Septiembre)

  Prop√≥sito: Documentar, de forma ejecutiva y reproducible, c√≥mo
  funcionan los scrapers, el pipeline de limpieza/consolidaci√≥n y los
  an√°lisis de septiembre para monitorear precios de aires acondicionados
  (mini‚Äësplit) en retailers de LATAM. Este README est√° listo para
  publicarse en GitHub.

------------------------------------------------------------------------

üéØ Objetivos del proyecto

-   Extraer precio regular y precio promoci√≥n de p√°ginas de producto de
    retailers.
-   Estandarizar campos clave: Retailer, Marca, Capacidad (BTU), Voltaje
    (110/115/220V), Tecnolog√≠a (Inverter/On‚ÄëOff), Modelo, Moneda,
    Precio_Normal, Precio_Promo, URL.
-   Consolidar snapshots mensuales (ej. Julio vs Septiembre) y generar
    tableros/CSV para an√°lisis.
-   Exportar entregables en Excel/CSV para pricing y benchmarking
    competitivo.

------------------------------------------------------------------------

üóÇÔ∏è Estructura sugerida del repo

    ac-latam-scraping/
    ‚îú‚îÄ scrapers/
    ‚îÇ  ‚îú‚îÄ alkosto_scraper.py
    ‚îÇ  ‚îú‚îÄ exito_scraper.py
    ‚îÇ  ‚îú‚îÄ olimpica_scraper.py
    ‚îÇ  ‚îú‚îÄ ... (otros retailers por pa√≠s)
    ‚îÇ  ‚îî‚îÄ utils_selectors.py
    ‚îú‚îÄ cleaners/
    ‚îÇ  ‚îú‚îÄ normalize_fields.py
    ‚îÇ  ‚îú‚îÄ dedupe_merge.py
    ‚îÇ  ‚îî‚îÄ currency_fx.py
    ‚îú‚îÄ analytics/
    ‚îÇ  ‚îú‚îÄ colombiaretailmkt.py     # an√°lisis exploratorio de septiembre (subido)
    ‚îÇ  ‚îî‚îÄ notebooks/               # opcional (EDA)
    ‚îú‚îÄ data/
    ‚îÇ  ‚îú‚îÄ raw/                     # snapshots crudos (YYYYMMDD_*.csv)
    ‚îÇ  ‚îú‚îÄ interim/                 # limpiezas intermedias
    ‚îÇ  ‚îî‚îÄ processed/               # consolidados (mensuales)
    ‚îú‚îÄ outputs/
    ‚îÇ  ‚îú‚îÄ excel/
    ‚îÇ  ‚îú‚îÄ charts/
    ‚îÇ  ‚îî‚îÄ csv/
    ‚îú‚îÄ .env.example
    ‚îú‚îÄ requirements.txt
    ‚îî‚îÄ README.md

  Nota: Los nombres de archivo exactos pueden variar. Este README resume
  c√≥mo funciona cada pieza en el pipeline de septiembre.

------------------------------------------------------------------------

‚öôÔ∏è Requisitos

-   Python 3.10+
-   Navegadores y drivers si usas Selenium; browsers instalados si usas
    Playwright.
-   Paquetes principales:
    -   pandas, numpy
    -   requests, beautifulsoup4 (para p√°ginas simples)
    -   selenium o playwright (para p√°ginas din√°micas)
    -   lxml, selectolax (parsing r√°pido)
    -   tenacity (reintentos)
    -   matplotlib, seaborn (gr√°ficas en an√°lisis)

Instalaci√≥n r√°pida:

    pip install -r requirements.txt
    # Playwright (si aplica)
    python -m playwright install

Variables de entorno (.env):

    # Ejemplo
    HEADLESS=true
    MAX_RETRIES=3
    REQUEST_TIMEOUT=20
    PROXY=
    USER_AGENT="Mozilla/5.0 (Windows NT 10.0; Win64; x64)..."

------------------------------------------------------------------------

üß™ C√≥mo correr el pipeline (Septiembre)

1.  Scraping por retailer (pa√≠s):

        python scrapers/alkosto_scraper.py --out data/raw/2025-09-xx_alkosto.csv
        python scrapers/exito_scraper.py   --out data/raw/2025-09-xx_exito.csv
        # ...

2.  Normalizaci√≥n y consolidaci√≥n:

        python cleaners/normalize_fields.py  --in data/raw --out data/interim/2025-09_normalized.csv
        python cleaners/dedupe_merge.py     --in data/interim/2025-09_normalized.csv                                        --out data/processed/2025-09_consolidated.csv

3.  An√°lisis (gr√°ficas/CSV):

        # Script de an√°lisis incluido
        python analytics/colombiaretailmkt.py

------------------------------------------------------------------------

üß© Scrapers de septiembre (comportamiento y salidas)

Cada scraper entrega un CSV con este esquema m√≠nimo (cabeceras):

    Retailer, Country, Brand, Model, Capacity, Voltage, Tech, Price_Normal, Price_Promo, Currency, Price_Type, URL, Timestamp

-   Price_Type: Normal o Promo (cuando el retailer separa
    expl√≠citamente).
-   Capacity: n√∫mero en BTU (ej. 9000, 12000, 18000, 24000).
-   Voltage: valores detectados del t√≠tulo/descripci√≥n (110/115/220V).
-   Tech: Inverter o On-Off.
-   Currency: moneda local del retailer; FX se maneja en
    cleaners/currency_fx.py.

üá®üá¥ Colombia (ejemplos)

scrapers/alkosto_scraper.py

-   Tipo de p√°gina: din√°mica con lazy loading e infinite scroll parcial.
-   T√©cnicas: Playwright/Selenium + esperas por selectores de tarjeta de
    producto.
-   Extracci√≥n: T√≠tulo, Marca, Modelo (si aparece), Precio lista, Precio
    promo, URL, badges (Inverter).
-   Voltaje: regex desde t√≠tulo/descripci√≥n (110V, 115V, 220V).
-   Salida: data/raw/2025-09-xx_alkosto.csv con Price_Type =
    Normal/Promo diferenciados.
-   Riesgos/Anti‚Äëbot: throttling y bloqueos por frecuencia; usar
    HEADLESS=true, USER_AGENT y sleep jitter.

scrapers/exito_scraper.py

-   Tipo de p√°gina: grid paginado con precios y badges de descuento.
-   Extracci√≥n: Igual a Alkosto; validar promo cuando hay % OFF.
-   Notas: Algunos modelos comparten PDP con variantes; normalizar por
    Model + Capacity.

scrapers/olimpica_scraper.py

-   Tipo de p√°gina: variantes por marca/capacidad en listados mixtos.
-   Extracci√≥n: T√≠tulo, Marca, Capacidad, Tecnolog√≠a; promo detectada
    por sello de oferta.
-   Voltaje: desde t√≠tulo (ej. 12.000 BTU 220V).

  Otros pa√≠ses (RD, VE, Guyana, Surinam) siguen el mismo patr√≥n: scraper
  por retailer ‚Üí CSV local ‚Üí normalizaci√≥n ‚Üí consolidado mensual.
  Ajustar selectors y waits seg√∫n cada UI.

------------------------------------------------------------------------

üßπ Limpieza y consolidaci√≥n (septiembre)

cleaners/normalize_fields.py

-   Prop√≥sito: Uniformizar cabeceras y valores para merge.
-   Acciones clave:
    -   strip + lower en cabeceras; mapping a est√°ndar (Price_Normal,
        Price_Promo, etc.).
    -   Regex para Capacity (BTU) y Voltage (110/115/220).
    -   Normalizaci√≥n de Brand (tabla de sin√≥nimos: LG = LG Electronics,
        MABE/Mabe, etc.).
    -   C√°lculo de RRP_USD (si hay Currency + TRM).
-   Salida: data/interim/2025-09_normalized.csv

cleaners/dedupe_merge.py

-   Prop√≥sito: Deduplicar y unir por clave [Retailer, Brand, Model,
    Capacity, Voltage, Tech].
-   Acciones: drop_duplicates, prioridad a filas con Price_Promo v√°lido
    y fecha m√°s reciente.
-   Salida: data/processed/2025-09_consolidated.csv

cleaners/currency_fx.py (opcional)

-   Prop√≥sito: Aplicar TRM/FX del d√≠a al campo RRP_USD.
-   Entradas: Currency, Local_Price.
-   Salida: agrega RRP_USD y TRM_Date.

------------------------------------------------------------------------

üìä An√°lisis de septiembre ‚Äî analytics/colombiaretailmkt.py

  Archivo incluido por ti y usado en septiembre. Resumen funcional:

Entradas: - datacomarketv3.csv (consolidado ya normalizado; contiene
Price_Type, RRP/TRM, RETIQ, Brand, Capacity, Estimate, etc.).

Pasos principales: 1. Estandarizaci√≥n de columnas (quita saltos de
l√≠nea/espacios) y rename: - RRP ‚Üí RRP_COP - TRM ‚Üí RRP_USD 2. Split por
tipo de precio: normal_prices vs promo_prices usando Price_Type. 3.
Gr√°fico Capacities vs RRP USD (scatter Normal vs Promo). 4. Merge por
Capacity entre Normal y Promo; c√°lculo de: -
Diferencia = RRP_USD_Normal - RRP_USD_Promo -
%Diferencia = (Diferencia / RRP_USD_Normal) * 100 - Gr√°fica de
diferencia absoluta y relativa por capacidad. 5. Promedios por Capacity
y RETIQ (barras de RRP_USD). 6. Clase C: groupby para Estimate ‚Üí
promedio, m√≠nimo, m√°ximo + gr√°ficas y data labels. 7. Clases C vs E:
groupby por Brand, RETIQ, Capacity ‚Üí barras de Precio_Promedio. 8. Clase
E por Marca/Capacidad: barras de Precio_Promedio (RRP_USD). 9. Funci√≥n
plot_min_max(...) (reutilizable): genera barras de m√≠nimo/m√°ximo por
Brand y Capacity, tanto para RRP_USD como Estimate.

Salidas/artefactos generados: - CSV:
brand_capacity_metrics_clase_c_e.csv - CSV:
class_e_metrics_rrp_usd.csv - Gr√°ficas: scatter, line (diferencias), bar
(promedios por clase, min/max por marca/capacidad).

Dependencias clave: pandas, matplotlib, seaborn.

  Este script est√° orientado al an√°lisis comparativo (no al scraping) y
  parte de un dataset consolidado (septiembre).

------------------------------------------------------------------------

üßæ Esquema de datos (m√≠nimo requerido)

  ------------------------------------------------------------------------
  Campo                          Tipo              Descripci√≥n
  ------------------------------ ----------------- -----------------------
  Retailer                       string            Nombre del retailer

  Country                        string            Pa√≠s del retailer

  Brand                          string            Marca del AC

  Model                          string            Modelo si disponible

  Capacity                       int               Capacidad en BTU (9000,
                                                   12000, 18000, 24000,
                                                   etc.)

  Voltage                        string            110/115/220V (extra√≠do
                                                   del t√≠tulo/descripci√≥n)

  Tech                           string            Inverter / On-Off

  Price_Normal                   float             Precio regular en
                                                   moneda local

  Price_Promo                    float             Precio promoci√≥n en
                                                   moneda local

  Currency                       string            Moneda local

  RRP_USD                        float             Precio referencial en
                                                   USD (si aplica TRM)

  Price_Type                     string            Normal / Promo

  URL                            string            Enlace a la PDP

  Timestamp                      datetime          Fecha/hora de captura
  ------------------------------------------------------------------------

------------------------------------------------------------------------

üßØ Troubleshooting (septiembre)

-   P√°ginas con scroll infinito: usar scroll step y wait_for_selector
    por card.
-   Precios din√°micos/JS: preferir Playwright; capturar XHR si la API es
    p√∫blica.
-   Duplicados por variante: normalizar Model y Capacity; dedupe por
    clave.
-   Promos impl√≠citas (% OFF): calcular Price_Promo a partir de
    Price_Normal y el % si el valor no aparece directo.
-   Bloqueos: rotar USER_AGENT, introducir jitter y limitar QPS; usar
    MAX_RETRIES.

------------------------------------------------------------------------

üìå Buenas pr√°cticas usadas en septiembre

-   Regex robustas para BTU y Voltaje desde t√≠tulos con formato libre.
-   Clasificador simple para Inverter/On‚ÄëOff por keywords y badges.
-   Convenciones de archivo: YYYY-MM-DD_retailer.csv y
    YYYY-MM_consolidated.csv.
-   Exportables Excel/CSV listos para negocio (pricing y benchmark).

------------------------------------------------------------------------

üó∫Ô∏è Roadmap corto

-   Agregar pruebas unitarias de selectors y parsers.
-   Headless CI (GitHub Actions) para snapshots semanales.
-   Conector a Google Sheets para compartir resultados en vivo.
-   Detecci√≥n de WiFi/R32/RETIQ m√°s precisa por ficha t√©cnica JSON‚ÄëLD.

------------------------------------------------------------------------

üì£ Cr√©ditos

-   L√≠der del proyecto: Mayerly Alviarez (AUX LATAM).
-   √öltima actualizaci√≥n: Septiembre 2025.
